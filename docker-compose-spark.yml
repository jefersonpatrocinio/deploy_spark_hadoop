version: '3.8'

x-deploy: &default-deploy
  replicas: 1
  restart_policy:
    condition: on-failure


x-deploy-manager: &default-deploy-manager
  <<: *default-deploy
  placement:
    constraints:
      - "node.role==manager"

x-deploy-worker: &default-deploy-worker
  <<: *default-deploy
  placement:
    constraints:
      - "node.role==worker"


services:
  spark-master:
    image: bde2020/spark-master:2.4.4-hadoop2.7
    hostname: spark-master
    extra_hosts:
      - "spark-master:0.0.0.0"
    ports:
      - "8080:8080"
      - "7077:7077"
    networks:
      - workbench
    deploy: *default-deploy-worker
    env_file:
      - ./hadoop.env

  spark-worker:
    image: bde2020/spark-worker:2.4.4-hadoop2.7
    container_name: spark-worker
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    networks:
      - workbench
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    deploy: *default-deploy-worker
    env_file:
      - ./hadoop.env

networks:
  workbench:
    external: true