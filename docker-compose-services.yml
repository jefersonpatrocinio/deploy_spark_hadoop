version: '3.8'

x-deploy: &default-deploy
  replicas: 1
  restart_policy:
    condition: on-failure


x-deploy-manager: &default-deploy-manager
  <<: *default-deploy
  placement:
    constraints:
      - "node.role==manager"

x-deploy-worker: &default-deploy-worker
  <<: *default-deploy
  placement:
    constraints:
      - "node.role==worker"


services:

  portainer:
    image: portainer/portainer
    container_name: portainer
    command: -H unix:///var/run/docker.sock
    restart: always
    ports:
      - 9000:9000
      - 8000:8000
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data
    deploy: *default-deploy-manager


  streaming:
    image: streaming_image
    extra_hosts:
      - "streaming:0.0.0.0"
    ports:
      - "5005:5005"
      - "41100:41100"
    environment:
      CORE_CONF_fs_defaultFS: "hdfs://namenode:8020"
      SPARK_MASTER: "spark://spark-master:7077"
      MASTER: "spark://spark-master:7077"
      SPARK_SUBMIT_OPTIONS: ""
    env_file:
      - ./hadoop.env
    deploy: *default-deploy-worker
    networks:
      - workbench

  dashboards:
    image: dashboards_image
    extra_hosts:
      - "dashboards:0.0.0.0"
    ports:
      - "5009:5009"
    deploy: *default-deploy-worker
    environment:
      - NAMENODE_HOST=namenode
    networks:
      - workbench

  twitter:
    image: twitter_image
    extra_hosts:
      - "twitter:0.0.0.0"
    ports:
      - "9017:9017"
    deploy: *default-deploy-worker
    environment:
      - NAMENODE_HOST=namenode
    networks:
      - workbench

networks:
  workbench:
    external: true